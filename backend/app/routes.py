from flask import Blueprint, request, jsonify, current_app
import os
import base64
from openai import OpenAI
import tempfile
import logging

# Create a Blueprint for the main application routes
main_bp = Blueprint('main', __name__)

@main_bp.route('/api/test', methods=['GET'])
def test_route():
    """
    Test endpoint to verify API connectivity
    
    Returns:
        JSON response with status and message
    """
    return jsonify({'status': 'success', 'message': 'API is working correctly'})

@main_bp.route('/api/analyze-image', methods=['POST', 'OPTIONS'])
def analyze_image():
    """
    Analyze an uploaded image using OpenAI's GPT-4 Vision API
    
    This endpoint accepts a POST request with an image file and returns
    a description of the image content generated by GPT-4.
    
    Returns:
        JSON response containing:
        - 'result': Image description (on success)
        - 'error': Error message (on failure)
    """
    # Handle CORS preflight request
    if request.method == 'OPTIONS':
        return '', 204
        
    try:
        # Log request information for debugging
        current_app.logger.info(f"Received request: {request.method} {request.path}")
        current_app.logger.info(f"Request headers: {dict(request.headers)}")
        current_app.logger.info(f"Request files: {request.files}")
        
        # Validate image file in request
        if 'image' not in request.files:
            current_app.logger.error("No image part in the request")
            return jsonify({'error': 'No image part in the request'}), 400
        
        file = request.files['image']
        
        # Validate file selection
        if file.filename == '':
            current_app.logger.error("No selected file")
            return jsonify({'error': 'No selected file'}), 400
        
        # Save file temporarily for processing
        temp_file = tempfile.NamedTemporaryFile(delete=False)
        file.save(temp_file.name)
        temp_file.close()
        
        # Initialize OpenAI client with API key
        api_key = os.environ.get("OPENAI_API_KEY")
        if not api_key:
            current_app.logger.error("OpenAI API key not found in environment variables")
            print("ERROR: OpenAI API key not found in environment variables")
            print(f"Environment variables: {os.environ.keys()}")
            return jsonify({'error': 'OpenAI API key not configured'}), 500
            
        current_app.logger.info(f"Using OpenAI API key: {api_key[:5]}...")
        client = OpenAI(
            api_key=api_key
        )
        
        # Convert image to base64 for OpenAI API
        with open(temp_file.name, "rb") as image_file:
            base64_image = base64.b64encode(image_file.read()).decode('utf-8')
        
        # Clean up temporary file
        os.unlink(temp_file.name)
        
        # Determine image format for proper MIME type
        image_format = "jpeg"
        if file.filename:
            ext = file.filename.split('.')[-1].lower()
            if ext in ['png', 'jpg', 'jpeg', 'gif', 'webp']:
                image_format = ext
        
        # Call OpenAI's GPT-4 Vision API
        current_app.logger.info("Calling OpenAI API")
        response = client.chat.completions.create(
            model="gpt-4-turbo",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text", 
                            "text": "Analyze this clothing item and return a JSON object with the following keys: "
                                  "category, color, brand (if visible), season (if applicable), and description. "
                                  "Format your entire response as a valid JSON object. "
                                  "Use simple lowercase strings for values. If something can't be identified, use null."
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/{image_format};base64,{base64_image}"
                            }
                        }
                    ]
                }
            ],
            max_tokens=500
        )
        
        # Extract the response and ensure it's valid JSON
        result = response.choices[0].message.content
        current_app.logger.info(f"OpenAI response received: {result[:50]}...")
        
        try:
            # Clean up the response by removing markdown formatting
            cleaned_result = result.strip()
            if cleaned_result.startswith('```json'):
                cleaned_result = cleaned_result[7:]  # Remove ```json prefix
            if cleaned_result.endswith('```'):
                cleaned_result = cleaned_result[:-3]  # Remove ``` suffix
            cleaned_result = cleaned_result.strip()
            
            # Try to parse the response as JSON to ensure it's valid
            import json
            parsed_result = json.loads(cleaned_result)
            print('parsed_result ->', parsed_result)
            # Return the JSON object to the frontend
            return jsonify(parsed_result)
        except json.JSONDecodeError as e:
            current_app.logger.error(f"Failed to parse OpenAI response as JSON: {str(e)}")
            return jsonify({
                'error': 'Invalid JSON response from OpenAI',
                'raw_response': result
            }), 500
    
    except Exception as e:
        current_app.logger.error(f"Error processing request: {str(e)}", exc_info=True)
        return jsonify({'error': str(e)}), 500